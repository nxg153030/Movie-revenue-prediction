{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "import numpy as np\n",
    "import ast\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def get_target_df(self, df, target):\n",
    "        '''returns target dataframe'''\n",
    "        return df[target]\n",
    "    \n",
    "    def get_non_numeric_columns(self, df):\n",
    "        '''Get non-numeric columns'''\n",
    "        non_float_columns = []\n",
    "        for col in df.columns:\n",
    "            if not is_numeric_dtype(df[col]):\n",
    "                non_float_columns.append(col)\n",
    "        return non_float_columns\n",
    "    \n",
    "    def get_numeric_columns(self, df):\n",
    "        '''Get numeric columns'''\n",
    "        numeric_columns = []\n",
    "        for col in df.columns:\n",
    "            if is_numeric_dtype(df[col]):\n",
    "                numeric_columns.append(col)\n",
    "        return numeric_columns\n",
    "    \n",
    "    def clean_data(self, df, drop_na):\n",
    "        '''fill null values and impute data'''\n",
    "        fn1 = lambda row: 0 if pd.isnull(row.homepage) else 1\n",
    "        fn2 = lambda row: 0 if pd.isnull(row.belongs_to_collection) else 1\n",
    "        fn3 = lambda row: 0 if pd.isnull(row.genres) else len(ast.literal_eval(row.genres))\n",
    "        fn4 = lambda row: 0 if pd.isnull(row.spoken_languages) else len(ast.literal_eval(row.spoken_languages))\n",
    "        fn5 = lambda row: 0 if pd.isnull(row.Keywords) else len(ast.literal_eval(row.Keywords))\n",
    "        fn6 = lambda row: 0 if pd.isnull(row.production_countries) else len(ast.literal_eval(row.production_countries))\n",
    "        fn7 = lambda row: 0 if pd.isnull(row.production_companies) else len(ast.literal_eval(row.production_companies))  \n",
    "        df['homepage'] = df.apply(fn1, axis=1)\n",
    "        df['belongs_to_collection'] = df.apply(fn2, axis=1)\n",
    "        df['genres'] = df.apply(fn3, axis=1)\n",
    "        df['spoken_languages'] = df.apply(fn4, axis=1)\n",
    "        df['Keywords'] = df.apply(fn5, axis=1)\n",
    "        df['production_countries'] = df.apply(fn6, axis=1)\n",
    "        df['production_companies'] = df.apply(fn7, axis=1)\n",
    "        df['original_language'] = df['original_language'].astype('category')\n",
    "        df['release_date'] = pd.to_datetime(df['release_date'])\n",
    "        df['release_date'] = [row.year for row in df['release_date']]\n",
    "        df['release_date'].fillna(df['release_date'].mean(), inplace=True)\n",
    "        df['release_date'] = df['release_date'].astype('category')\n",
    "        df['runtime'].fillna(df['runtime'].mean(), inplace=True)\n",
    "\n",
    "        df = df.drop(['imdb_id', 'cast', 'crew', 'status',\n",
    "                            'poster_path', 'tagline', 'title', 'overview', 'original_title'], axis=1)\n",
    "        return df\n",
    "    \n",
    "    def encode_features(self, df):\n",
    "        '''Encode the features'''\n",
    "        columns = ['original_language', 'release_date']\n",
    "        le = LabelEncoder()\n",
    "        for col in columns:\n",
    "            df[col] = le.fit_transform(df[col])\n",
    "        return df\n",
    "    \n",
    "    def create_train_df(self, train_feature_file, target, preprocessing):\n",
    "        '''Prepare training data'''\n",
    "        train_feature_df = self.load_data(train_feature_file)       \n",
    "        if preprocessing:\n",
    "            train_feature_df = self.clean_data(train_feature_df, drop_na=True)\n",
    "            train_feature_df = self.encode_features(train_feature_df)\n",
    "        target_df = self.get_target_df(train_feature_df, target)\n",
    "        train_df = train_feature_df.drop(['id', target], axis=1)\n",
    "        return train_df, target_df\n",
    "    \n",
    "    def create_test_df(self, test_file):\n",
    "        '''Prepare testing data'''\n",
    "        test_df = self.load_data(test_file)\n",
    "        test_df = self.clean_data(test_df, drop_na=False)\n",
    "        test_df = self.encode_features(test_df)\n",
    "        test_rowids = test_df['id']\n",
    "        test_df = test_df.drop(['id'], axis=1)\n",
    "        return test_df, test_rowids\n",
    "        \n",
    "    def load_data(self, file):\n",
    "        '''Load the data'''\n",
    "        return pd.read_csv(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, target_df = data.create_train_df('train.csv', target='revenue', preprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df, test_rowids = data.create_test_df('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_df, target_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Linear Regression </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_revenue_y_preds = reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [ 5.50704393e+07  2.41196481e+00 -2.92633837e+06  2.04183588e+07\n",
      "  2.28899414e+05  2.24814316e+06 -3.93514465e+06 -3.27512208e+06\n",
      " -2.29647598e+05  3.04345234e+05 -3.06980608e+06  7.81170271e+05]\n",
      "Mean squared error: 6006561556819613.00\n",
      "Variance score: 0.64\n"
     ]
    }
   ],
   "source": [
    "reg.score(X_test, y_test)\n",
    "print('Coefficients: \\n', reg.coef_)\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % mean_squared_error(y_test, movie_revenue_y_preds))\n",
    "# Explained variance score\n",
    "print('Variance score: %.2f' % r2_score(y_test, movie_revenue_y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Random Forest </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1000, num = 10)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 100, num = 10)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "# parameters for random forest\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(sklearn.metrics.SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:   17.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:   17.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "                   estimator=RandomForestRegressor(bootstrap=True,\n",
       "                                                   criterion='mse',\n",
       "                                                   max_depth=None,\n",
       "                                                   max_features='auto',\n",
       "                                                   max_leaf_nodes=None,\n",
       "                                                   min_impurity_decrease=0.0,\n",
       "                                                   min_impurity_split=None,\n",
       "                                                   min_samples_leaf=1,\n",
       "                                                   min_samples_split=2,\n",
       "                                                   min_weight_fraction_leaf=0.0,\n",
       "                                                   n_estimators='warn',\n",
       "                                                   n_jobs=None, oob_score=False,\n",
       "                                                   random_sta...\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [100, 200, 300, 400,\n",
       "                                                         500, 600, 700, 800,\n",
       "                                                         900, 1000]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "                   return_train_score=False, scoring='neg_mean_squared_error',\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestRegressor()\n",
    "rf_random = RandomizedSearchCV(estimator = rfc, param_distributions = random_grid, n_iter = 15, cv = 3, \n",
    "                               scoring='neg_mean_squared_error', verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 500,\n",
       " 'min_samples_split': 10,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 70,\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = rf_random.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 4461092132013514.00\n",
      "Variance score: 0.73\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, y_preds))\n",
    "# Explained variance score\n",
    "print('Variance score: %.2f' % r2_score(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on test data\n",
    "preds = rf_random.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'id': test_rowids, 'revenue': preds}\n",
    "results = pd.DataFrame(d)\n",
    "# save results to csv\n",
    "results.to_csv(\"results.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_nlp",
   "language": "python",
   "name": "env_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
